{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "unet_resnet34_ADC.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTHyrTD_zbLz"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-5L8TXNzzmj"
      },
      "source": [
        "#content to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgNtTd96pQ4R"
      },
      "source": [
        "!pip install tensorflow==2.2.0\n",
        "!pip install keras==2.4.2\n",
        "!pip install segmentation_models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI44rQXeS0op"
      },
      "source": [
        "# Enter modules\n",
        "import zipfile  # For faster extraction\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from numpy import expand_dims\n",
        "import cv2 # for read image\n",
        "import numpy as np # For data manipulation\n",
        "import matplotlib.pyplot as plt # for draw\n",
        "from google.colab.patches import cv2_imshow #coordinate cv2 with colab\n",
        "import nibabel as nib  #To read nii format\n",
        "import re  # For parsing the filenames (to know their modality)\n",
        "import glob # For populating the list of files\n",
        "import imgaug.augmenters as iaa #for data agumention\n",
        "from sklearn.model_selection import KFold, StratifiedKFold #Data setup and data segmentation\n",
        "import imgaug as ia\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import CSVLogger\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import datetime\n",
        "import os\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow.keras.backend as K\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import segmentation_models as sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlfy-NngUywP"
      },
      "source": [
        "import os\n",
        "import nibabel as nib\n",
        "ADC=os.listdir('/content/drive/MyDrive/prostate_crop/ADC_crop')\n",
        "\n",
        "\n",
        "ADC_imag=[]\n",
        "X=[]\n",
        "for i in ADC:\n",
        "  ADC_imag.append('/content/drive/MyDrive/prostate_crop/ADC_crop/' + i )\n",
        "for j in ADC_imag:\n",
        "  img= nib.load(j)\n",
        "  adc_img = img.get_fdata(caching='unchanged') \n",
        "  X.append(adc_img)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EtCx8_TVFRn"
      },
      "source": [
        "label=os.listdir('/content/drive/MyDrive/prostate_crop/Label_crop')\n",
        "label_imag=[]\n",
        "Y=[]\n",
        "\n",
        "for i in label:\n",
        "  label_imag.append('/content/drive/MyDrive/prostate_crop/Label_crop/' + i )\n",
        "for j in label_imag:\n",
        "  img= nib.load(j)\n",
        "  lbl_img = img.get_fdata(caching='unchanged') \n",
        "  Y.append(lbl_img)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBmCSN_0Q8b4"
      },
      "source": [
        "X=np.array(X)\n",
        "Y=np.array(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QMCTJ63yaqyK"
      },
      "source": [
        "np.unique(Y[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8k13i5_RbOM"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "i=0 \n",
        "n_split=10\n",
        " \n",
        "for train_index,test_index in KFold(n_split).split(X):\n",
        "  if i==0:\n",
        "    X_train,X_val=X[train_index],X[test_index]\n",
        "    y_train,y_val=Y[train_index],Y[test_index]\n",
        "  i=i+1  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "810BUvPKYMRB"
      },
      "source": [
        "X_T=[]\n",
        "for i in range (0,len(X_train)):\n",
        "  for j in range(0,19):\n",
        "    img=X_train[i][:,:,j]\n",
        "    X_T.append(img)\n",
        "\n",
        "Y_T=[]\n",
        "for i in range (0,len(y_train)):\n",
        "  for j in range(0,19):\n",
        "    img=y_train[i][:,:,j]\n",
        "    Y_T.append(img)    \n",
        "\n",
        "X_V=[]\n",
        "for i in range (0,len(X_val)):\n",
        "  for j in range(0,19):\n",
        "    img=X_val[i][:,:,j]\n",
        "    X_V.append(img) \n",
        "Y_V=[]\n",
        "for i in range (0,len(y_val)):\n",
        "  for j in range(0,19):\n",
        "    img=y_val[i][:,:,j]\n",
        "    Y_V.append(img)              "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppGdiny9X7w1"
      },
      "source": [
        "np.unique(Y_V[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHOLIdPlBHCB"
      },
      "source": [
        "plt.imshow(Y_T[7])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OubS12Ygbxjc"
      },
      "source": [
        "Y_T_c=to_categorical(Y_T,5)\n",
        "Y_V_c=to_categorical(Y_V,5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MAHenSqICad"
      },
      "source": [
        "np.unique(Y_T_c[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10i_GjTaqoby"
      },
      "source": [
        "X_T=np.array(X_T)\n",
        "Y_T_c=np.array(Y_T_c)\n",
        "X_V=np.array(X_V)\n",
        "Y_V_c=np.array(Y_V_c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC1Y49AigGtO"
      },
      "source": [
        "X_T=np.expand_dims(X_T, axis=-1)\n",
        "X_V=np.expand_dims(X_V, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA9dgqO_xvsu"
      },
      "source": [
        "import random\n",
        "def Data_generator_train(X,y, batch_size=8):   \n",
        "    while True:               \n",
        "          for start in range(0, X.shape[0], batch_size):\n",
        "              x_batch = []\n",
        "              y_batch = []\n",
        "              end = min(start + batch_size, X.shape[0])\n",
        "              ids_batch = X[start:end]\n",
        "              for idd in range(start,end):           \n",
        "                   a=random.randint(0,2)\n",
        "                   if a==0:\n",
        "                      image =np.fliplr(X[idd]) \n",
        "                      label =np.fliplr(y[idd])\n",
        "                   if a==1:\n",
        "                     image =np.flipud(X[idd]) \n",
        "                     label =np.flipud(y[idd])\n",
        "                   elif a==2:\n",
        "                     image =(X[idd]) \n",
        "                     label =(y[idd])                \n",
        "                   x_batch.append(image)\n",
        "                   y_batch.append(label)               \n",
        "              x_batch= np.array(x_batch)\n",
        "              y_batch= np.array(y_batch)                                           \n",
        "              yield x_batch, y_batch\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWYHRJEB0Fm8"
      },
      "source": [
        "m,b=next(iter(Data_generator_train(X_T,Y_T_c)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvEvuaoVU9S-"
      },
      "source": [
        "import random\n",
        "def Data_generator_test(X,y, batch_size=1):   \n",
        "    while True:               \n",
        "          for start in range(0, X.shape[0], batch_size):\n",
        "              x_batch = []\n",
        "              y_batch = []\n",
        "              end = min(start + batch_size, X.shape[0])\n",
        "              ids_batch = X[start:end]\n",
        "              for idd in range(start,end):           \n",
        "                image =(X[idd]) \n",
        "                label =(y[idd])                \n",
        "                x_batch.append(image)\n",
        "                y_batch.append(label)               \n",
        "              x_batch= np.array(x_batch)\n",
        "              y_batch= np.array(y_batch)                                           \n",
        "              yield x_batch, y_batch\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZ5XVIQeXGjZ"
      },
      "source": [
        "m,b=next(iter(Data_generator_test(X_V,Y_V_c)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJf3JLotqrhh"
      },
      "source": [
        "model= sm.Unet('resnet34', classes=5, activation='softmax', encoder_weights=None, input_shape=(160, 160, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1gPL-1urCwb"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELk4IPu9sH5e"
      },
      "source": [
        "optim = tf.keras.optimizers.Adam(lr =0.0008)\n",
        "dice_loss = sm.losses.DiceLoss() \n",
        "focal_loss = sm.losses.CategoricalFocalLoss()\n",
        "total_loss = dice_loss + (1 * focal_loss)\n",
        "\n",
        "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5), 'accuracy']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvcIKttMsJWX"
      },
      "source": [
        "model.compile(optim, total_loss, metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYVRphMrsMVd"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint,CSVLogger\n",
        "\n",
        "model_checkpoint = ModelCheckpoint('/content/drive/My Drive/unet_resnet34_ADC/'+'unet_resnet34_fold1.h5', save_best_only=True,save_weights_only=True, verbose=2, monitor='val_f1-score',mode='max')\n",
        "csv_logger = CSVLogger('/content/drive/My Drive/unet_resnet34_ADC/'+'unet_resnet34_fold1.csv', append=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0S9Ph5lhsZfn"
      },
      "source": [
        "def step_decay(epoch):\n",
        "     \n",
        "     initAlpha = 0.0008\n",
        "     factor = .9\n",
        "     dropEvery = 30\n",
        "     alpha = initAlpha * (factor ** np.floor((1 + epoch) / dropEvery))\n",
        "     return float(alpha)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjgPBPk57OMO"
      },
      "source": [
        "batch_size =8\n",
        "TrainSteps = len(X_T)  / batch_size\n",
        "ValSteps   = len(X_V)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faoRSxQ37UsS"
      },
      "source": [
        "# %%time\n",
        "# from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "# history = model.fit_generator(Data_generator_train(X_T,Y_T_c), epochs = 50 , steps_per_epoch=TrainSteps, validation_data =Data_generator_test(X_V,Y_V_c) ,\n",
        "#                 validation_steps =ValSteps,\n",
        "#                callbacks=[model_checkpoint, csv_logger, LearningRateScheduler(step_decay)],shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRyQMql5PjUs"
      },
      "source": [
        "# plt.figure(figsize=(30, 5))\n",
        "# plt.subplot(121)\n",
        "# plt.plot(history.history['f1-score'])\n",
        "# plt.plot(history.history['val_f1-score'])\n",
        "\n",
        "# plt.title('Model Dice_score_unet_resnet34_fold1')\n",
        "# plt.ylabel('dice_score')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "# # Plot training & validation loss values\n",
        "# plt.subplot(122)\n",
        "# plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "# plt.title('Model loss_unet_resnet34_fold1')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.legend(['Train', 'Test'], loc='upper left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2OTKPC4QPzK9"
      },
      "source": [
        "# plt.figure(figsize=(30, 5))\n",
        "# plt.subplot(121)\n",
        "# plt.plot(history.history['iou_score'])\n",
        "# plt.plot(history.history['val_iou_score'])\n",
        "\n",
        "# plt.title('Model iou_score_unet_resnet34_fold1')\n",
        "# plt.ylabel('iou_score')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "# # Plot training & validation loss values\n",
        "# plt.subplot(122)\n",
        "# plt.plot(history.history['accuracy'])\n",
        "# plt.plot(history.history['val_accuracy'])\n",
        "# plt.title('Model accuracy_unet_resnet34_fold1')\n",
        "# plt.ylabel('accuracy')\n",
        "# plt.xlabel('Epoch')\n",
        "# plt.legend(['Train', 'Test'], loc='upper left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fSZaxtzTjX8"
      },
      "source": [
        "model.load_weights('/content/drive/My Drive/unet_resnet34_ADC/unet_resnet34_fold1.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzLWu7oehsr6"
      },
      "source": [
        "scores=model.evaluate(X_V,Y_V_c , batch_size=1)\n",
        "print(\"Loss: {:.5}\".format(scores[0]))\n",
        "for metric, value in zip(metrics, scores[1:]):\n",
        "    print(\"mean {}: {:.5}\".format(metric, value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qd9RjCV55qX"
      },
      "source": [
        "p=model.predict(X_V)\n",
        "y=Y_V_c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import directed_hausdorff\n",
        "\n",
        "\n",
        "def Average(lst):\n",
        "    return sum(lst) / len(lst)\n",
        "\n",
        "\n",
        "\n",
        "HD=[]\n",
        "for i in range(0,76):\n",
        "  hd=directed_hausdorff(p[i,:,:,0], y[i,:,:,0])\n",
        "  HD.append(hd[0])\n",
        "\n"
      ],
      "metadata": {
        "id": "XizYdJdFPcm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import directed_hausdorff\n",
        "\n",
        "\n",
        "def Average(lst):\n",
        "    return sum(lst) / len(lst)\n",
        "\n",
        "\n",
        "\n",
        "HD=[]\n",
        "for i in range(0,76):\n",
        "  hd=directed_hausdorff(p[i,:,:,1], y[i,:,:,1])\n",
        "  HD.append(hd[0])\n",
        "\n"
      ],
      "metadata": {
        "id": "_tDQJTrrPhAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import directed_hausdorff\n",
        "\n",
        "\n",
        "def Average(lst):\n",
        "    return sum(lst) / len(lst)\n",
        "\n",
        "\n",
        "\n",
        "HD=[]\n",
        "for i in range(0,76):\n",
        "  hd=directed_hausdorff(p[i,:,:,2], y[i,:,:,2])\n",
        "  HD.append(hd[0])\n"
      ],
      "metadata": {
        "id": "2O_dEcPgPhDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import directed_hausdorff\n",
        "\n",
        "\n",
        "def Average(lst):\n",
        "    return sum(lst) / len(lst)\n",
        "\n",
        "\n",
        "\n",
        "HD=[]\n",
        "for i in range(0,76):\n",
        "  hd=directed_hausdorff(p[i,:,:,3], y[i,:,:,3])\n",
        "  HD.append(hd[0])\n"
      ],
      "metadata": {
        "id": "7kIrZzDGPhGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial.distance import directed_hausdorff\n",
        "\n",
        "\n",
        "def Average(lst):\n",
        "    return sum(lst) / len(lst)\n",
        "\n",
        "\n",
        "\n",
        "HD=[]\n",
        "for i in range(0,76):\n",
        "  hd=directed_hausdorff(p[i,:,:,4], y[i,:,:,4])\n",
        "  HD.append(hd[0])\n",
        "\n"
      ],
      "metadata": {
        "id": "Nf7rRX5fPjvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9Ocsy_M6EXN"
      },
      "source": [
        "pred=np.argmax(p, axis=-1)\n",
        "ytrue=np.argmax(y, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNpitLFlIu74"
      },
      "source": [
        "Pred=pred.flatten()\n",
        "Ytrue=ytrue.flatten()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpw5SbEGJmho"
      },
      "source": [
        "Ytrue.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2hF-PdTKKEp"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "classification_report(Pred, Ytrue, digits=4)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}